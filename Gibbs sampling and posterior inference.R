rm(list=ls(all=TRUE))
library(MCMCpack)
library(mvtnorm)
library(rstudioapi)
library(ggplot2)
library(scales)

script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
script_path <- getSourceEditorContext()$path
script_dir <- dirname(script_path)

file_path <- file.path(script_dir, "GoogleSearchIndex.txt")
dat <- read.delim(file_path)

dat$Week <- as.Date(dat$Week)

# EDA
ggplot(dat, aes(x = Week, y = covid)) +
  geom_line(color = "brown1", linewidth = 1) +  
  geom_point(color = "brown1", size = 3) +    
  labs(
    title = "Public Interest in COVID-19 Over Time (Google Search Index)",
    x = "Date",
    y = "Search Index"
  ) +
  theme_minimal() +  
  scale_x_date(
    date_breaks = "3 months",       
    date_labels = "%Y-%m",          
    limits = c(min(dat$Week), max(dat$Week))     
  )


y=as.numeric(dat$covid)
print(length(y))


#### Model setup
n.all = n.all = length(y)
p=1 ## order of AR process
K=2 ## number of mixing component

Y = matrix(y[(p + 1):n.all], ncol = 1) ## y_{p+1:T}

Fmtx = sapply(1:p, function(k) {
  y[(p + 1 - k):(n.all - k)]
})
Fmtx = t(Fmtx)
print(Fmtx)

n=length(Y) ## T-p 

## prior hyperparameters
m0 = matrix(rep(0, p), ncol=1)     ## AR ç³»æ•°çš„å…ˆéªŒå‡å€¼ï¼ˆéžä¿¡æ¯æ€§ï¼Œ0 å‘é‡ï¼‰
C0 = 10 * diag(p)                  ## AR ç³»æ•°å…ˆéªŒåæ–¹å·®çŸ©é˜µï¼Œè¾ƒå¤§è¡¨ç¤ºä¸ç¡®å®šæ€§é«˜
n0 = 0.02                          ## æ®‹å·®æ–¹å·®çš„ inverse-gamma å…ˆéªŒè‡ªç”±åº¦
d0 = 0.02                          ## æ®‹å·®æ–¹å·®çš„ inverse-gamma å…ˆéªŒå°ºåº¦å‚æ•°
a = rep(1, K)                      ## Dirichlet å…ˆéªŒå‚æ•°ï¼ˆå‡åŒ€å…ˆéªŒï¼‰ï¼Œç”¨äºŽ omega çš„é‡‡æ ·


#ä½¿ç”¨çš„æ˜¯ Dirichlet å…±è½­é‡‡æ ·ï¼ŒåŽéªŒå‚æ•°ä¸º a + æˆåˆ†é¢‘æ•°
sample_omega = function(L.cur){
  n.vec = sapply(1:K, function(k){ sum(L.cur == k) })  ## ç»Ÿè®¡æ¯ä¸ªæˆåˆ†è¢«åˆ†é…äº†å¤šå°‘æ•°æ®ç‚¹
  rdirichlet(1, a + n.vec)                            ## Dirichlet åŽéªŒé‡‡æ ·æƒé‡
}


#å¯¹äºŽå•ä¸ªæ—¶é—´ç‚¹tï¼Œæˆ‘ä»¬ä¸çŸ¥é“å®ƒæ¥è‡ªå“ªä¸ªæˆåˆ†kï¼Œè¿™ä¸ªå‡½æ•°å°è¯•ä¼°è®¡é‚£ä¸ªæ¦‚çŽ‡å¹¶é‡‡æ ·
sample_L_one = function(beta.cur, omega.cur, nu.cur, y.cur, Fmtx.cur){
  prob_k = function(k){
    beta.use = beta.cur[((k-1)*p + 1):(k*p)]            ## å–å‡ºç¬¬ k ä¸ª AR æˆåˆ†çš„ç³»æ•°
    mu = sum(beta.use * Fmtx.cur)                       ## å½“å‰æ—¶é—´ç‚¹çš„é¢„æµ‹å€¼
    omega.cur[k] * (dnorm(y.cur, mean=mu, sd=sqrt(nu.cur)) + 1e-10)  ## æˆåˆ†æƒé‡ Ã— å¯¹åº”çš„é«˜æ–¯å¯†åº¦å€¼
  }

  prob.vec = sapply(1:K, prob_k)                         ## å¾—åˆ°æ¯ä¸ªæˆåˆ†çš„ï¼ˆéžæ ‡å‡†åŒ–ï¼‰æ¦‚çŽ‡
  prob.vec = prob.vec + 1e-10

  L.sample = sample(1:K, 1, prob = (prob.vec + 1e-8) / sum(prob.vec + 1e-8)) ## æŒ‰ç…§å½’ä¸€åŒ–åŽçš„æ¦‚çŽ‡è¿›è¡Œé‡‡æ ·
  return(L.sample)
}

#DSä¿®æ”¹ç‰ˆæœ¬
sample_L_one <- function(beta.cur, omega.cur, nu.cur, y.cur, Fmtx.cur, DEBUG = TRUE) {
  prob_k <- function(k) {
    beta.use <- beta.cur[((k-1)*p + 1):(k*p)]            # å–å‡ºç¬¬ k ä¸ª AR æˆåˆ†çš„ç³»æ•°
    mu <- sum(beta.use * Fmtx.cur)                       # å½“å‰æ—¶é—´ç‚¹çš„é¢„æµ‹å€¼
    likelihood <- dnorm(y.cur, mean = mu, sd = sqrt(nu.cur))
    prob <- omega.cur[k] * (likelihood + 1e-10)          # æˆåˆ†æƒé‡ Ã— é«˜æ–¯å¯†åº¦å€¼
    
    if (DEBUG) {
      cat(sprintf(
        "[DEBUG prob_k] k=%d | beta.use=%s | mu=%.3f | likelihood=%.3e | omega=%.3f | prob=%.3e\n",
        k, paste(round(beta.use, 3), collapse = ","), mu, likelihood, omega.cur[k], prob
      ))
    }
    
    return(prob)
  }
  
  prob.vec <- sapply(1:K, prob_k)                       # å¾—åˆ°æ¯ä¸ªæˆåˆ†çš„éžæ ‡å‡†åŒ–æ¦‚çŽ‡
  prob.vec <- prob.vec + 1e-10                         # é¿å…æ•°å€¼ä¸‹æº¢
  
  if (DEBUG) {
    cat("[DEBUG prob.vec] Raw prob.vec =", paste(round(prob.vec, 5), collapse = ", "), "\n")
    cat("[DEBUG prob.vec] Normalized prob.vec =", 
        paste(round(prob.vec / sum(prob.vec), 5), collapse = ", "), "\n")
  }
  
  L.sample <- sample(1:K, 1, prob = (prob.vec + 1e-8) / sum(prob.vec + 1e-8))  # å½’ä¸€åŒ–åŽé‡‡æ ·
  
  if (DEBUG) {
    cat("[DEBUG L.sample] Sampled L =", L.sample, "\n\n")
  }
  
  return(L.sample)
}


#é‡‡æ ·æ•´æ¡åºåˆ—çš„æ ‡ç­¾å‘é‡ ð¿1:ð‘›
sample_L=function(y,x,beta.cur,omega.cur,nu.cur){
  L.new=sapply(1:n, function(j){sample_L_one(beta.cur,omega.cur,nu.cur,y.cur=y[j,],Fmtx.cur=x[,j])})
  return(L.new)
}

#é‡‡æ ·å™ªå£°æ–¹å·®
sample_nu = function(L.cur, beta.cur) {
  n.star = n0 + n  #n.starä¸ºæ®‹å·®æ–¹å·®çš„ Inverse-Gamma åŽéªŒè‡ªç”±åº¦å‚æ•°
  err.y = function(idx) {
    L.use = L.cur[idx]                             # å½“å‰è§‚æµ‹å±žäºŽå“ªä¸ªæˆåˆ† k
    beta.use = beta.cur[((L.use - 1) * p + 1):(L.use * p)]  # æ‹¿åˆ°è¯¥æˆåˆ†çš„ beta
    err = Y[idx, ] - sum(Fmtx[, idx] * beta.use)   # è®¡ç®—è¯¥è§‚æµ‹ç‚¹çš„é¢„æµ‹è¯¯å·®
    return(err^2)
  }
  d.star = d0 + sum(sapply(1:n, err.y))            # åŽéªŒ IG çš„å°ºåº¦å‚æ•°
  1 / rgamma(1, shape = n.star / 2, rate = d.star / 2)  # ä»Ž Inverse-Gamma ä¸­é‡‡æ ·
}

#é‡‡æ ·æˆåˆ†kçš„ARç³»æ•°
# ä¿®æ”¹sample_betaå‡½æ•°ä¸­çš„éƒ¨åˆ†ä»£ç 
sample_beta = function(k, L.cur, nu.cur) {
  idx.select = (L.cur == k)
  n.k = sum(idx.select)
  if (n.k == 0) {
    m.k = m0
    C.k = C0
  } else {
    y.tilde.k = Y[idx.select, , drop = FALSE]  # ä¿æŒçŸ©é˜µç»“æž„
    Fmtx.tilde.k = Fmtx[, idx.select, drop = FALSE]  # ä¿æŒçŸ©é˜µç»“æž„
    e.k = y.tilde.k - t(Fmtx.tilde.k) %*% m0
    Q.k = t(Fmtx.tilde.k) %*% C0 %*% Fmtx.tilde.k + diag(n.k)
    Q.k.inv = chol2inv(chol(Q.k))
    A.k = C0 %*% Fmtx.tilde.k %*% Q.k.inv
    m.k = m0 + A.k %*% e.k
    C.k = C0 - A.k %*% Q.k %*% t(A.k)
  }
  
  rmvnorm(1, m.k, nu.cur * C.k)
}

# ç¡®ä¿åœ¨sample_Lå‡½æ•°ä¸­ä¼ é€’Fmtxåˆ—æ—¶ä¿æŒçŸ©é˜µç»“æž„
sample_L = function(y, x, beta.cur, omega.cur, nu.cur) {
  L.new = sapply(1:n, function(j) {
    sample_L_one(beta.cur, omega.cur, nu.cur, y.cur = y[j, , drop = FALSE], Fmtx.cur = x[, j, drop = FALSE])
  })
  return(L.new)
}

# æ€»ç»“ï¼Œæ²¡æœ‰è¢«åˆ†é…åˆ°ç‚¹çš„æˆåˆ†ä¹Ÿå¿…é¡»æ›´æ–°ï¼Œä½†æ˜¯ç”¨çš„æ˜¯å…ˆéªŒ


#### MCMC setup
nsim = 1000  ## è®¾å®šé‡‡æ ·è¿­ä»£æ¬¡æ•°

## å­˜å‚¨æ¯æ¬¡è¿­ä»£åŽçš„å‚æ•°ç»“æžœ
beta.mtx  = matrix(0, nrow = p*K, ncol = nsim)  ## æ¯è¡Œæ˜¯ beta_1, ..., beta_K çš„æ‹¼æŽ¥
L.mtx     = matrix(0, nrow = n,    ncol = nsim) ## æ¯ä¸€åˆ—å­˜å‚¨å½“å‰ Lï¼ˆå“ªä¸ªè§‚æµ‹å±žäºŽå“ªä¸ªæˆåˆ†ï¼‰
omega.mtx = matrix(0, nrow = K,    ncol = nsim) ## æ¯æ¬¡è¿­ä»£æ··åˆæƒé‡å‘é‡ omega
nu.vec    = rep(0, nsim)                        ## æ¯æ¬¡è¿­ä»£å™ªå£°æ–¹å·® nu

beta.cur  = rep(0, p*K)       ## æ¯ä¸ªæˆåˆ†çš„ beta ç³»æ•°åˆå§‹è®¾ä¸º 0
L.cur     = rep(1, n)         ## åˆå§‹å‡è®¾æ‰€æœ‰ç‚¹éƒ½å±žäºŽç¬¬ä¸€ä¸ªæˆåˆ†
omega.cur = rep(1/K, K)       ## åˆå§‹ omega å¹³å‡åˆ†é…ï¼ˆå‡åŒ€ï¼‰
nu.cur    = 1                 ## åˆå§‹å™ªå£°æ–¹å·®è®¾ä¸º 1


## Gibbs Sampler
# è®¾ç½®æµ‹è¯•æ¨¡å¼å¼€å…³
# è®¾ç½®æµ‹è¯•æ¨¡å¼å¼€å…³
TEST <- FALSE  # è®¾ç½®ä¸ºTRUEå¼€å¯è¯¦ç»†è¾“å‡ºï¼ŒFALSEå…³é—­

for (i in 1:nsim) {
  set.seed(i)
  
  ## sample omega
  omega.cur <- sample_omega(L.cur)
  omega.mtx[, i] <- omega.cur
  
  # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°omegaï¼ˆä¿®æ­£æ‹¬å·ï¼‰
  if (TEST) {
    print(paste("Iteration", i, "| omega =", 
                paste(round(omega.cur, 3), collapse=", ")))  # æ³¨æ„æ­¤å¤„é—­åˆä¸‰ä¸ªæ‹¬å·
  }
  
  ## sample L
  L.cur <- sample_L(Y, Fmtx, beta.cur, omega.cur, nu.cur)
  L.mtx[, i] <- L.cur
  
  # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°Lçš„åˆ†å¸ƒç»Ÿè®¡
  if (TEST) {
    l_counts <- table(factor(L.cur, levels=1:K))
    print(paste("Iteration", i, "| L counts:", paste(l_counts, collapse=", ")))
  }
  
  ## sample nu
  nu.cur <- sample_nu(L.cur, beta.cur)
  nu.vec[i] <- nu.cur
  
  # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°nu
  if (TEST) {
    print(paste("Iteration", i, "| nu =", round(nu.cur, 3)))
  }
  
  ## sample beta
  beta.cur <- as.vector(sapply(1:K, function(k) { sample_beta(k, L.cur, nu.cur) }))
  beta.mtx[, i] <- beta.cur
  
  # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°beta
  if (TEST) {
    print(paste("Iteration", i, "| beta =", 
                paste(round(beta.cur, 3), collapse=", ")))  # åŒæ ·ä¿®æ­£æ­¤å¤„æ‹¬å·
  }
  
  ## å¸¸è§„è¿›åº¦æç¤ºï¼ˆæ— è®ºTESTæ˜¯å¦å¼€å¯ï¼‰
  if (i %% 1000 == 0) {
    print(paste("Number of iterations:", i))
  }
}

#### show the result
#åŽ 10,000 æ¬¡è¢«è®¤ä¸ºå·²ç»æ”¶æ•›åˆ°åŽéªŒåˆ†å¸ƒï¼Œå¯ç”¨äºŽç»Ÿè®¡æŽ¨æ–­ï¼ˆå¦‚é¢„æµ‹ï¼‰
sample.select.idx=seq(5001,10000,by=1)

#æ ¹æ®åŽéªŒæ ·æœ¬è¿›è¡Œé¢„æµ‹
post.pred.y.mix=function(idx){
  
  k.vec.use=L.mtx[,idx]
  beta.use=beta.mtx[,idx]
  nu.use=nu.vec[idx]
  
  
  get.mean=function(s){
    k.use=k.vec.use[s]
    sum(Fmtx[,s]*beta.use[((k.use-1)*p+1):(k.use*p)])
  }
  mu.y=sapply(1:n, get.mean)
  ## ç»™ç¬¬ k ä¸ªæ—¶é—´ç‚¹ï¼Œç”Ÿæˆä¸€ä¸ªé¢„æµ‹å€¼
  sapply(1:length(mu.y), function(k){rnorm(1,mu.y[k],sqrt(nu.use))})
  
}  
#y.post.pred.sampleæ˜¯å¯¹æ‰€æœ‰ç‚¹çš„åŽéªŒé¢„æµ‹
y.post.pred.sample=sapply(sample.select.idx, post.pred.y.mix)

summary.vec95=function(vec){
  c(unname(quantile(vec,0.025)),mean(vec),unname(quantile(vec,0.975)))
}

summary.y=apply(y.post.pred.sample,MARGIN=1,summary.vec95)

#plot posterior inference
library(ggplot2)

n <- length(Y)  # æœ‰æ•ˆè§‚æµ‹é•¿åº¦
df_plot <- data.frame(
  Time   = 1:n,
  Truth  = Y,
  Mean   = summary.y[2, ],
  Lower  = summary.y[1, ],
  Upper  = summary.y[3, ]
)

# ä¸‹é¢ç”¨ ggplot2 ç»˜å›¾
p <- ggplot(df_plot, aes(x = Time)) +
  # çœŸå®žå€¼ï¼šé»‘è‰²çº¿+ç‚¹
  geom_line(aes(y = Truth, color = "Truth"), size = 0.8) +
  geom_point(aes(y = Truth, color = "Truth"), size = 1.5) +
  
  geom_line(aes(y = Mean, color = "Mean"), size = 0.8, linetype = "dashed") +
  geom_point(aes(y = Mean, color = "Mean"), size = 1.5, shape = 4) +
 
  geom_ribbon(aes(ymin = Lower, ymax = Upper, fill = "95% C.I."), alpha = 0.2) +
  
  # color
  scale_color_manual(values = c("Truth" = "black", "Mean" = "grey")) +
  scale_fill_manual(values  = c("95% C.I." = "purple")) +
  
  labs(x = "Time", y = "", color = "", fill = "") +
  theme_minimal()

print(p)

check_normal_density <- function(x) {
  density <- dnorm(x, mean = 0, sd = 1)
  
  cat("Value:", x, "\n")
  cat("Density under N(0,1):", format(density, scientific = TRUE), "\n")
  
  if (density < 1e-10) {
    cat("âš ï¸  WARNING: This density is extremely small â€” potential underflow risk!\n")
  } else {
    cat("âœ…  Density is within normal range.\n")
  }
  
  return(invisible(density))
}
check_normal_density(81)      
check_normal_density(8) 


